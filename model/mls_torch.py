import torch
import torch.nn as nn
import numpy as np

class MotionEstimation(nn.Module):
    def __init__(self):
        super(MotionEstimation,self).__init__()
    def forward(self,sp, dp):
        b, _, _= sp.shape
        affine, M, W, phat, qhat = self.mls_affine_deformation(sp, dp)
        return  affine, M, W, phat, qhat
      
      
    def make_coordinate_grid(self,spatial_size, type):
        """
        Create a meshgrid [-1,1] x [-1,1] of given spatial_size.
        """
        h, w = spatial_size
        x = torch.arange(w).type(type)
        y = torch.arange(h).type(type)
        # x = x / w
        # y =  y / h  
        x = (2 * (x / (w - 1)) - 1)
        y = (2 * (y / (h - 1)) - 1)
        yy = y.view(-1, 1).repeat(1, w)
        xx = x.view(1, -1).repeat(h, 1)
        meshed = torch.cat([xx.unsqueeze_(2), yy.unsqueeze_(2)], 2)
        return meshed
    def mls_affine_deformation(self,p, q, alpha=1.0, eps=1e-8):
        batch,num,_=p.shape
        v=self.make_coordinate_grid((32,32),torch.float32).permute(1,2,0).cuda()
        reshaped_v=v.reshape(1,2,32,32)
        reshaped_p = p.reshape(batch,num, 2, 1, 1)
        reshaped_q=q.reshape(batch,num,2,1,1)
        w=torch.zeros(batch,num,32,32).cuda()
        for i in range(batch):
            w[i]=1/(torch.sum((reshaped_q[i]-reshaped_v)**2,axis=1)+eps)**1
            w[i]/=torch.sum(w[i],dim=1,keepdim=True)
        pstar=torch.zeros(batch,2,32,32).cuda()
        qstar=torch.zeros(batch,2,32,32).cuda()
        for i in range(batch):
            for j in range(num):
                pstar+=w[i][j]*reshaped_p[i][j]
                qstar+=w[i][j]*reshaped_q[i][j]
        p_hat=reshaped_p-pstar.unsqueeze(1)
        q_hat=reshaped_q-qstar.unsqueeze(1)
        reshaped_w = w.reshape(batch,num, 1, 1, 32, 32)
        p_hat=p_hat.reshape(batch,num,2,1,32,32)
        q_hat=q_hat.reshape(batch,num,2,1,32,32)
        q_hat1=q_hat.reshape(batch,num,1,2,32,32)
        pTwp = torch.zeros((batch,2, 2, 32, 32)).cuda()
        for i in range(batch):
            for j in range(num):
                pTwp += q_hat[i][j] * reshaped_w[i][j] * q_hat1[i][j]
        del q_hat1

        try:
            inv_pTwp = torch.linalg.inv(pTwp.permute(0,3,4,1,2))                            # [grow, gcol, 2, 2]
            flag=False
        except:
            flag=True
            det=torch.linalg.det(pTwp.permute(0,3,4,1,2)) 
            det[det<eps]=float('inf')
            reshaped_det = det.reshape(batch,1, 1, 32, 32)                                    # [1, 1, grow, gcol]
            adjoint = pTwp[:,[[1, 0], [1, 0]], [[1, 1], [0, 0]], :, :]                        # [2, 2, grow, gcol]
            adjoint[:,[0, 1], [1, 0], :, :] = -adjoint[:,[0, 1], [1, 0], :, :]                  # [2, 2, grow, gcol]
            inv_pTwp = (adjoint / reshaped_det).permute(0,3,4,1,2)                       # [grow, gcol, 2, 2]
    
        mul_left = reshaped_v - qstar                                                       # [2, grow, gcol]
        reshaped_mul_left = mul_left.reshape(batch,1, 2, 32, 32).permute(0,3, 4, 1, 2)        # [grow, gcol, 1, 2]
        mul_right = torch.multiply(reshaped_w,q_hat)                                 # [ctrls, 2, 1, grow, gcol]
        reshaped_mul_right=mul_right.permute(0,1,4,5,2,3)
        A=torch.zeros(batch,num,32,32,1,1).cuda()
        for i in range(batch):
            temp=torch.matmul(torch.matmul(reshaped_mul_left[i],inv_pTwp[i]),reshaped_mul_right[i])
            A[i]=temp
        A=A.reshape(batch,num,1,32,32)
        
        transformers=torch.zeros(batch,2,32,32).cuda()
        for i in range(batch):
            for j in range(num):
                transformers+=A[i][j]*(reshaped_q[i][j]-qstar[i])
        del A
        transformers[transformers < 0] = 0
        transformers[transformers>1]=-1
        transformers[:][0][transformers[:][0] > 1] = 0
        transformers[:][1][transformers[:][1] > 1] = 0 
        # if transformers[:][0]>1:
        #     transformers[:][0]=1
        # print(w)
        return transformers,pTwp,w,p_hat,q_hat






def mls_similarity_deformation(vy, vx, p, q, alpha=1.0, eps=1e-8):
    """ Similarity deformation

    Parameters
    ----------
    vx, vy: ndarray
        coordinate grid, generated by torch.meshgrid(gridX, gridY)
    p: ndarray
        an array with size [n, 2], original control points
    q: ndarray
        an array with size [n, 2], final control points
    alpha: float
        parameter used by weights
    eps: float
        epsilon

    Return
    ------
        A deformed image.
    """
    # Change (x, y) to (row, col)
    q = q[:, [1, 0]].to(torch.int16)
    p = p[:, [1, 0]].to(torch.int16)
    # Exchange p and q and hence we transform destination pixels to the corresponding source pixels.
    p, q = q, p

    grow = vx.shape[0]  # grid rows
    gcol = vx.shape[1]  # grid cols
    ctrls = p.shape[0]  # control points

    # Compute
    # [ctrls, 2, 1, 1]
    reshaped_p = p.reshape(ctrls, 2, 1, 1)
    reshaped_v = torch.vstack(
        (vx.reshape(1, grow, gcol), vy.reshape(1, grow, gcol)))      # [2, grow, gcol]

    w = 1.0 / (torch.sum((reshaped_p - reshaped_v).to(torch.float32)
               ** 2, axis=1) + eps) ** alpha    # [ctrls, grow, gcol]
    # [ctrls, grow, gcol]
    w /= torch.sum(w, axis=0, keepdims=True)

    pstar = torch.zeros((2, grow, gcol))
    for i in range(ctrls):
        # [2, grow, gcol]
        pstar += w[i] * reshaped_p[i]

    # [ctrls, 2, grow, gcol]
    phat = reshaped_p - pstar
    # [ctrls, 1, 2, grow, gcol]
    reshaped_phat = phat.reshape(ctrls, 1, 2, grow, gcol)
    # [ctrls, 1, 1, grow, gcol]
    reshaped_w = w.reshape(ctrls, 1, 1, grow, gcol)

    mu = torch.zeros((grow, gcol))
    for i in range(ctrls):
        mu += w[i] * (phat[i] ** 2).sum(0)
    # [1, grow, gcol]
    reshaped_mu = mu.reshape(1, grow, gcol)

    # [2, grow, gcol]
    vpstar = reshaped_v - pstar
    # [2, 1, grow, gcol]
    reshaped_vpstar = vpstar.reshape(2, 1, grow, gcol)
    # [2, grow, gcol]
    neg_vpstar_verti = vpstar[[1, 0], ...]
    neg_vpstar_verti[1, ...] = -neg_vpstar_verti[1, ...]
    reshaped_neg_vpstar_verti = neg_vpstar_verti.reshape(
        2, 1, grow, gcol)              # [2, 1, grow, gcol]
    # [2, 2, grow, gcol]
    mul_right = torch.cat((reshaped_vpstar, reshaped_neg_vpstar_verti), axis=1)

    # Calculate q
    # [ctrls, 2, 1, 1]
    reshaped_q = q.reshape((ctrls, 2, 1, 1))
    qstar = torch.zeros((2, grow, gcol))
    for i in range(ctrls):
        # [2, grow, gcol]
        qstar += w[i] * reshaped_q[i]

    # Get final image transfomer -- 3-D array
    temp = torch.zeros((grow, gcol, 2))
    for i in range(ctrls):
        # [2, grow, gcol]
        neg_phat_verti = phat[i, [1, 0]]
        neg_phat_verti[1] = -neg_phat_verti[1]
        reshaped_neg_phat_verti = neg_phat_verti.reshape(
            1, 2, grow, gcol)              # [1, 2, grow, gcol]
        # [2, 2, grow, gcol]
        mul_left = torch.cat(
            (reshaped_phat[i], reshaped_neg_phat_verti), axis=0)

        A = torch.matmul((reshaped_w[i] * mul_left).permute(2, 3, 0, 1),
                         mul_right.permute(2, 3, 0, 1))                                  # [grow, gcol, 2, 2]

        # [2, grow, gcol]
        qhat = reshaped_q[i] - qstar
        reshaped_qhat = qhat.reshape(1, 2, grow, gcol).permute(
            2, 3, 0, 1)            # [grow, gcol, 1, 2]

        # Get final image transfomer -- 3-D array
        # [grow, gcol, 2]
        temp += torch.matmul(reshaped_qhat, A).reshape(grow, gcol, 2)

    # [2, grow, gcol]
    transformers = temp.permute(2, 0, 1) / reshaped_mu + qstar

    # Removed the points outside the border
    transformers[transformers < 0] = 0
    transformers[0][transformers[0] > grow - 1] = 0
    transformers[1][transformers[1] > gcol - 1] = 0

    return transformers


def mls_rigid_deformation(vy, vx, p, q, alpha=1.0, eps=1e-8):
    """ Rigid deformation

    Parameters
    ----------
    vx, vy: ndarray
        coordinate grid, generated by torch.meshgrid(gridX, gridY)
    p: ndarray
        an array with size [n, 2], original control points
    q: ndarray
        an array with size [n, 2], final control points
    alpha: float
        parameter used by weights
    eps: float
        epsilon

    Return
    ------
        A deformed image.
    """
    # Change (x, y) to (row, col)

    q = q[:, [1, 0]].to(torch.int16)
    p = p[:, [1, 0]].to(torch.int16)
    # Exchange p and q and hence we transform destination pixels to the corresponding source pixels.
    p, q = q, p

    grow = vx.shape[0]  # grid rows
    gcol = vx.shape[1]  # grid cols
    ctrls = p.shape[0]  # control points

    # Compute
    # [ctrls, 2, 1, 1]
    reshaped_p = p.reshape(ctrls, 2, 1, 1)
    reshaped_v = torch.vstack(
        (vx.reshape(1, grow, gcol), vy.reshape(1, grow, gcol)))      # [2, grow, gcol]

    w = 1.0 / (torch.sum((reshaped_p - reshaped_v).to(torch.float32)
               ** 2, axis=1) + eps) ** alpha    # [ctrls, grow, gcol]
    # [ctrls, grow, gcol]
    w /= torch.sum(w, axis=0, keepdims=True)

    pstar = torch.zeros((2, grow, gcol))
    for i in range(ctrls):
        # [2, grow, gcol]
        pstar += w[i] * reshaped_p[i]

    # [2, grow, gcol]
    vpstar = reshaped_v - pstar
    # [2, 1, grow, gcol]
    reshaped_vpstar = vpstar.reshape(2, 1, grow, gcol)
    # [2, grow, gcol]
    neg_vpstar_verti = vpstar[[1, 0], ...]
    neg_vpstar_verti[1, ...] = -neg_vpstar_verti[1, ...]
    reshaped_neg_vpstar_verti = neg_vpstar_verti.reshape(
        2, 1, grow, gcol)              # [2, 1, grow, gcol]
    # [2, 2, grow, gcol]
    mul_right = torch.cat((reshaped_vpstar, reshaped_neg_vpstar_verti), axis=1)
    reshaped_mul_right = mul_right.reshape(
        2, 2, grow, gcol)                            # [2, 2, grow, gcol]

    # Calculate q
    # [ctrls, 2, 1, 1]
    reshaped_q = q.reshape((ctrls, 2, 1, 1))
    qstar = torch.zeros((2, grow, gcol))
    for i in range(ctrls):
        # [2, grow, gcol]
        qstar += w[i] * reshaped_q[i]

    temp = torch.zeros((grow, gcol, 2))
    for i in range(ctrls):
        # [2, grow, gcol]
        phat = reshaped_p[i] - pstar
        # [1, 2, grow, gcol]
        reshaped_phat = phat.reshape(1, 2, grow, gcol)
        # [1, 1, grow, gcol]
        reshaped_w = w[i].reshape(1, 1, grow, gcol)
        # [2, grow, gcol]
        neg_phat_verti = phat[[1, 0]]
        neg_phat_verti[1] = -neg_phat_verti[1]
        reshaped_neg_phat_verti = neg_phat_verti.reshape(
            1, 2, grow, gcol)              # [1, 2, grow, gcol]
        # [2, 2, grow, gcol]
        mul_left = torch.cat((reshaped_phat, reshaped_neg_phat_verti), axis=0)

        A = torch.matmul((reshaped_w * mul_left).permute(2, 3, 0, 1),
                         reshaped_mul_right.permute(2, 3, 0, 1))                       # [grow, gcol, 2, 2]

        # [2, grow, gcol]
        qhat = reshaped_q[i] - qstar
        reshaped_qhat = qhat.reshape(1, 2, grow, gcol).permute(
            2, 3, 0, 1)            # [grow, gcol, 1, 2]

        # Get final image transfomer -- 3-D array
        # [grow, gcol, 2]
        temp += torch.matmul(reshaped_qhat, A).reshape(grow, gcol, 2)

    # [2, grow, gcol]
    temp = temp.permute(2, 0, 1)
    # [1, grow, gcol]
    normed_temp = torch.linalg.norm(temp, axis=0, keepdims=True)
    normed_vpstar = torch.linalg.norm(
        vpstar, axis=0, keepdims=True)                       # [1, grow, gcol]
    transformers = temp / normed_temp * normed_vpstar + \
        qstar                          # [2, grow, gcol]

    # Removed the points outside the border
    transformers[transformers < 0] = 0
    transformers[0][transformers[0] > grow - 1] = 0
    transformers[1][transformers[1] > gcol - 1] = 0

    return transformers  # .to(torch.device("cuda"))


if __name__ == "__main__":

    import cv2
    import numpy as np
    img = cv2.imread("img/toy.jpg")
    h, w, _ = img.shape
    print(h, w)
    p = torch.tensor([
        [30, 155], [125, 155], [225, 155],
        [100, 235], [160, 235], [85, 295], [180, 293]
    ])
    q = torch.tensor([
        [42, 211], [125, 155], [235, 100],
        [80, 235], [140, 235], [85, 295], [180, 295]
    ])
    gridX = torch.arange(w, dtype=torch.int16)
    gridY = torch.arange(h, dtype=torch.int16)
    vy, vx = torch.meshgrid(gridX, gridY)
    affine = mls_affine_deformation(vy, vx, p, q, alpha=1)
    similar = mls_similarity_deformation(vy, vx, p, q, alpha=1)
    rigid = mls_rigid_deformation(vy, vx, p, q, alpha=1)
    print(affine.shape, similar.shape, rigid.shape)
    # cv2.imshow("test",aug1)
    # cv2.waitKey(0)
